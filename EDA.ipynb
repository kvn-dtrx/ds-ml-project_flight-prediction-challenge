{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Power predictive score\n",
    "import ppscore as pps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_TRAIN = \"./data/train.csv\"\n",
    "\n",
    "RSEED = 42\n",
    "DPI = 600\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"STATUS\"].unique())\n",
    "\n",
    "col_entries = [\"ATA\", \"DEP\", \"RTR\", \"SCH\", \"DEL\"]\n",
    "\n",
    "for year in col_entries:\n",
    "    print(f\"Number of entries of {year}: {df[df['STATUS'] == year].shape[0]}\")\n",
    "    print(f\"Mean: {df[df['STATUS'] == year]['target'].mean()}\")\n",
    "    print(f\"Median: {df[df['STATUS'] == year]['target'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"STA\"] = df[\"STA\"].str.replace(\".\", \":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATOP\"] = pd.to_datetime(df[\"DATOP\"], format=\"%Y-%m-%d\")\n",
    "df[\"STD\"] = pd.to_datetime(df[\"STD\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"STA\"] = pd.to_datetime(df[\"STA\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year, month, dayofweek and hour information out of column publish_time and build new column for each\n",
    "df[\"DATOP_year\"]=df[\"DATOP\"].dt.year\n",
    "df[\"DATOP_month\"]=df[\"DATOP\"].dt.month\n",
    "df[\"DATOP_day\"]=df[\"DATOP\"].dt.dayofweek+1\n",
    "#df[\"publish_hour\"]=df[\"publish_time\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flight_time\"] = (df[\"STA\"] - df[\"STD\"]).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"STATUS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DATOP",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "FLTID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DEPSTN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ARRSTN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "STD",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "STA",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "STATUS",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AC",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1b676b07-4009-4a7f-a3cd-efa30ad2dfc0",
       "rows": [
        [
         "0",
         "train_id_0",
         "2016-01-03",
         "TU 0712 ",
         "CMN",
         "TUN",
         "2016-01-03 10:30:00",
         "2016-01-03 12.55.00",
         "ATA",
         "TU 32AIMN",
         "260.0"
        ],
        [
         "1",
         "train_id_1",
         "2016-01-13",
         "TU 0757 ",
         "MXP",
         "TUN",
         "2016-01-13 15:05:00",
         "2016-01-13 16.55.00",
         "ATA",
         "TU 31BIMO",
         "20.0"
        ],
        [
         "2",
         "train_id_2",
         "2016-01-16",
         "TU 0214 ",
         "TUN",
         "IST",
         "2016-01-16 04:10:00",
         "2016-01-16 06.45.00",
         "ATA",
         "TU 32AIMN",
         "0.0"
        ],
        [
         "3",
         "train_id_3",
         "2016-01-17",
         "TU 0480 ",
         "DJE",
         "NTE",
         "2016-01-17 14:10:00",
         "2016-01-17 17.00.00",
         "ATA",
         "TU 736IOK",
         "0.0"
        ],
        [
         "4",
         "train_id_4",
         "2016-01-17",
         "TU 0338 ",
         "TUN",
         "ALG",
         "2016-01-17 14:30:00",
         "2016-01-17 15.50.00",
         "ATA",
         "TU 320IMU",
         "22.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATOP</th>\n",
       "      <th>FLTID</th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>AC</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>TU 0712</td>\n",
       "      <td>CMN</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-03 10:30:00</td>\n",
       "      <td>2016-01-03 12.55.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>TU 0757</td>\n",
       "      <td>MXP</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-13 15:05:00</td>\n",
       "      <td>2016-01-13 16.55.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 31BIMO</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>TU 0214</td>\n",
       "      <td>TUN</td>\n",
       "      <td>IST</td>\n",
       "      <td>2016-01-16 04:10:00</td>\n",
       "      <td>2016-01-16 06.45.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0480</td>\n",
       "      <td>DJE</td>\n",
       "      <td>NTE</td>\n",
       "      <td>2016-01-17 14:10:00</td>\n",
       "      <td>2016-01-17 17.00.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0338</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ALG</td>\n",
       "      <td>2016-01-17 14:30:00</td>\n",
       "      <td>2016-01-17 15.50.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 320IMU</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       DATOP     FLTID DEPSTN ARRSTN                  STD  \\\n",
       "0  train_id_0  2016-01-03  TU 0712     CMN    TUN  2016-01-03 10:30:00   \n",
       "1  train_id_1  2016-01-13  TU 0757     MXP    TUN  2016-01-13 15:05:00   \n",
       "2  train_id_2  2016-01-16  TU 0214     TUN    IST  2016-01-16 04:10:00   \n",
       "3  train_id_3  2016-01-17  TU 0480     DJE    NTE  2016-01-17 14:10:00   \n",
       "4  train_id_4  2016-01-17  TU 0338     TUN    ALG  2016-01-17 14:30:00   \n",
       "\n",
       "                   STA STATUS         AC  target  \n",
       "0  2016-01-03 12.55.00    ATA  TU 32AIMN   260.0  \n",
       "1  2016-01-13 16.55.00    ATA  TU 31BIMO    20.0  \n",
       "2  2016-01-16 06.45.00    ATA  TU 32AIMN     0.0  \n",
       "3  2016-01-17 17.00.00    ATA  TU 736IOK     0.0  \n",
       "4  2016-01-17 15.50.00    ATA  TU 320IMU    22.0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n",
    "# df[\"DEPSTN\"].nunique()\n",
    "# df[\"ARRSTN\"].nunique()\n",
    "# pps.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_scores = pps.matrix(df)[[\"x\", \"y\", \"ppscore\"]].pivot(\n",
    "    columns=\"x\", index=\"y\", values=\"ppscore\"\n",
    ")\n",
    "pp_scores = pp_scores.round(2)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pp_scores, vmin=0, vmax=1, cmap=\"Reds\", linewidths=0.5, annot=True)\n",
    "\n",
    "\n",
    "plt.savefig(\"./img/pp-scores.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "\n",
    "plt.savefig(\"./img/pairplot.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOP_years = df[\"DATOP_year\"].unique()\n",
    "\n",
    "for year in DATOP_years:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df_year = df[df[\"DATOP_year\"] == year]\n",
    "    df_year[\"DATOP_month\"].hist(bins=12)\n",
    "    plt.title(f\"Flight Distribution per Month â€“ {year}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Flights\")\n",
    "    plt.xticks(range(1, 13))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in DATOP_years:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df_year = df[df[\"DATOP_year\"] == year]\n",
    "    df_year.groupby(\"DATOP_month\")[\"target\"].sum().plot(\n",
    "        kind=\"line\",\n",
    "        title=f\"Monthly Sum of Target for {year}\",\n",
    "        xlabel=\"Month\",\n",
    "        ylabel=\"Sum of Target\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (a.k.a. a Feeble Try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['AC'], prefix='AC')\n",
    "\n",
    "y = df.target\n",
    "X = df_encoded.drop(\"target\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RSEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_encoded.columns if col.startswith(\"AC_\")]\n",
    "\n",
    "X_0 = X_train[cols]\n",
    "y_0 = y_train\n",
    "X_1 = X_test[cols]\n",
    "y_1 = y_test\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [\n",
    "        3,\n",
    "        # 5, 7, 9\n",
    "    ],\n",
    "    \"weights\": [\"uniform\", \"distance\"],  # Weighting scheme\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"],  # Distance metric\n",
    "}\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, cv=5, scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "# Fit the grid search to training data\n",
    "grid_search.fit(X_0, y_0)\n",
    "\n",
    "\n",
    "# # model = LinearRegression()\n",
    "# model = KNeighborsRegressor(n_neighbors=500)\n",
    "\n",
    "# model.fit(X_0, y_0)\n",
    "\n",
    "y_pred = model.predict(X_1)\n",
    "\n",
    "mse = mean_squared_error(y_1, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_1, y_pred)\n",
    "\n",
    "# Display results\n",
    "# print(\"Coefficients:\", linreg.coef_)\n",
    "# print(\"Intercept:\", model.intercept_)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "# print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaningin and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this exercise we will only deal with numeric variables\n",
    "\n",
    "X = coffee_features.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Quakers column and unnamed\n",
    "#changing one of the altitude to log and droping the original\n",
    "X_train[\"altitude_mean_log\"] = np.log(X_train[\"altitude_mean_meters\"])\n",
    "X_train.drop(['altitude_mean_meters'], axis=1, inplace=True)\n",
    "X_train.drop(['Quakers'], axis=1, inplace=True)\n",
    "X_train.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altitude_low_meters_mean = X_train[\"altitude_low_meters\"].mean()\n",
    "altitude_high_meters_mean = X_train[\"altitude_high_meters\"].mean()\n",
    "altitude_mean_log_mean = X_train[\"altitude_mean_log\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with mean.. \n",
    "X_train[\"altitude_low_meters\"] = X_train[\"altitude_low_meters\"].fillna(altitude_low_meters_mean)\n",
    "X_train[\"altitude_high_meters\"] = X_train[\"altitude_high_meters\"].fillna(altitude_high_meters_mean)\n",
    "X_train[\"altitude_mean_log\"] = X_train[\"altitude_mean_log\"].fillna(altitude_mean_log_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"altitude low meters mean is {altitude_low_meters_mean}\")\n",
    "print(f\"altitude_high_meters_mean is {altitude_high_meters_mean}\")\n",
    "print(f\"altitude_mean_log_mean is {altitude_mean_log_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in order to exemplify how the predict will work.. we will save the y_train\n",
    "X_test.to_csv(\"data/X_test.csv\")\n",
    "y_test.to_csv(\"data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_train_pred = reg.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Quakers column and unnamed\n",
    "#changing one of the altitude to log and droping the original\n",
    "X_test[\"altitude_mean_log\"] = np.log(X_test[\"altitude_mean_meters\"])\n",
    "X_test.drop(['altitude_mean_meters'], axis=1, inplace=True)\n",
    "X_test.drop(['Quakers'], axis=1, inplace=True)\n",
    "X_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# fillna with mean.. \n",
    "X_test[\"altitude_low_meters\"] = X_test[\"altitude_low_meters\"].fillna(altitude_low_meters_mean)\n",
    "X_test[\"altitude_high_meters\"] = X_test[\"altitude_high_meters\"].fillna(altitude_high_meters_mean)\n",
    "X_test[\"altitude_mean_log\"] = X_test[\"altitude_mean_log\"].fillna(altitude_mean_log_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
