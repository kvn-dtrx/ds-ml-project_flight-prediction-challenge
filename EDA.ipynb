{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS ML Project ⟡ Flight Delay Prediction Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "**TODO** Write this paragraph\n",
    "\n",
    "This notebook represents our analysis of the [flight delay dataset for Tunisair](https://zindi.africa/competitions/flight-delay-prediction-challenge) from [Zindi](https://zindi.africa) \n",
    "\n",
    "At last: \"our\" refers to ...\n",
    "- [greseberisha](https://github.com/greseberisha)\n",
    "- [MoSeBaur](https://github.com/MoSeBaur)\n",
    "- [kvn-dtrx](https://github.com/kvn-dtrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "\n",
    "# Scientific Computation\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Scikit-Learn Tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Power predictive score\n",
    "import ppscore as pps\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs\n",
    "\n",
    "Next, let us specify all required configurations to have them in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level of the warnings module\n",
    "WARNINGS_LEVEL = \"ignore\"\n",
    "warnings.filterwarnings(WARNINGS_LEVEL)\n",
    "\n",
    "# Path to train data\n",
    "PATH_DATA_TRAIN = \"./data/train.csv\"\n",
    "\n",
    "# Random seed\n",
    "RSEED = 42\n",
    "\n",
    "# Resolution when storing plots in files\n",
    "DPI = 600\n",
    "\n",
    "# Matplotlib style\n",
    "PLT_STYLE = \"seaborn\"\n",
    "try:\n",
    "    plt.style.use(PLT_STYLE)\n",
    "except:\n",
    "    warnings.warn(f\"Could not load matplotlib style {PLT_STYLE}\", UserWarning)\n",
    "\n",
    "# Whether to run long computations\n",
    "RUN_LONG_COMPUTATIONS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the data from file into a pandas data frame and create a copy that will incorporate our manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv(PATH_DATA_TRAIN)\n",
    "\n",
    "df = df_0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.head())\n",
    "# print(df.shape)\n",
    "# print(df.isnull().sum())\n",
    "# print(df.dtypes)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable definitions (according to <https://zindi.africa/competitions/flight-delay-prediction-challenge/data>):\n",
    "\n",
    "Present in the data:\n",
    "\n",
    "| Column      | Description                  |\n",
    "|-------------|------------------------------|\n",
    "| ID          | Unique identifier for the flight. |\n",
    "| DATOP       | Date of flight.                 |\n",
    "| FLTID       | Flight number.                  |\n",
    "| DEPSTN      | Departure point (station/airport). |\n",
    "| ARRSTN      | Arrival point (station/airport). |\n",
    "| STD         | Scheduled Time of Departure.    |\n",
    "| STA         | Scheduled Time of Arrival.      |\n",
    "| STATUS      | Flight status (e.g., delayed, canceled). |\n",
    "| AC          | Aircraft code.                 |\n",
    "| target      | Flight delay (in minutes).      |\n",
    "\n",
    "\n",
    "Not present in the data:\n",
    "\n",
    "| Column | Description        |\n",
    "|-------------|--------------------|\n",
    "| ETD         | Expected Time departure |\n",
    "| ETA         | Expected Time arrival   |\n",
    "| ATD         | Actual Time of Departure |\n",
    "| ATA         | Actual Time of arrival   |\n",
    "| DELAY1      | Delay code 1            |\n",
    "| DUR1        | Delay time 1            |\n",
    "| DELAY2      | Delay code 2            |\n",
    "| DUR2        | Delay time 2            |\n",
    "| DELAY3      | Delay code 3            |\n",
    "| DUR3        | Delay time 3            |\n",
    "| DELAY4      | Delay code 4            |\n",
    "| DUR4        | Delay time 4            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorry for \"statuses\" ...\n",
    "statuses = df[\"STATUS\"].unique()\n",
    "\n",
    "print(\"All Statuses:\")\n",
    "for status in statuses:\n",
    "    print(f\"  Number of entries of {status}: {df[df['STATUS'] == status].shape[0]}\")\n",
    "    print(f\"  Mean: {df[df['STATUS'] == status]['target'].mean()}\")\n",
    "    print(f\"  Median: {df[df['STATUS'] == status]['target'].median()}\")\n",
    "\n",
    "for status in statuses:\n",
    "    df[df[\"STATUS\"] == status][\"target\"].hist(\n",
    "        bins=50,\n",
    "        log=False,\n",
    "    )\n",
    "    plt.title(status)\n",
    "    plt.xlabel(\"Delay\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.savefig(f\"./img/delay-to-sum-flight-on-status-eq-{status}_hist.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Code | Name              | Description                                                                 |\n",
    "|------|-------------------|-----------------------------------------------------------------------------|\n",
    "| ATA  | Actual Time Arrival| Flights that successfully landed at their destination.                     |\n",
    "| DEP  | Departed          | Flights that departed but may not have completed their journey.             |\n",
    "| RTR  | Returned          | Flights that took off but returned to the departure airport due to issues.  |\n",
    "| SCH  | Scheduled         | Flights listed in the schedule, no delay data applicable.                   |\n",
    "| DEL  | Canceled          | Flights that were canceled, treated as permanent delays.                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of DEP remains a bit obscure ... in a first approximation, we drop it. Further, it is hard to measure the delay of a DEL flight (a possibility for regular flights would be to take the duration between the DEL flight and the next flight that indeed arrives plus the delay of that flight). But we also decide us simply for dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"STATUS\"].isin([\"DEP\", \"DEL\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\"airports.csv\")\n",
    "airports = airports[['iata_code', 'iso_country']]  # keep only what we need\n",
    "airports = airports.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(airports[['iata_code', 'iso_country']], left_on='DEPSTN', right_on='iata_code', how='left')\n",
    "df.drop(columns='iata_code', inplace=True)\n",
    "df.rename(columns={'iso_country': 'country_dep'}, inplace=True)\n",
    "\n",
    "df = df.merge(airports[['iata_code', 'iso_country']], left_on='ARRSTN', right_on='iata_code', how='left')\n",
    "df.drop(columns='iata_code', inplace=True)\n",
    "df.rename(columns={'iso_country': 'country_arr'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "def iso_to_continent(iso):\n",
    "    try:\n",
    "        continent_code = pc.country_alpha2_to_continent_code(iso)\n",
    "        return pc.convert_continent_code_to_continent_name(continent_code)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['continent_dep'] = df['country_dep'].apply(iso_to_continent)\n",
    "df['continent_arr'] = df['country_arr'].apply(iso_to_continent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].hist(\n",
    "    bins=100, \n",
    "    log=False,\n",
    ")\n",
    "plt.xlabel(\"Delay\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(1, 500)\n",
    "\n",
    "plt.savefig(f\"./img/delay-to-sum-flight_hist.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATOP\"] = pd.to_datetime(df[\"DATOP\"], format=\"%Y-%m-%d\")\n",
    "df[\"STD\"] = pd.to_datetime(df[\"STD\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"STA\"] = pd.to_datetime(df[\"STA\"], format=\"%Y-%m-%d %H.%M.%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year, month, dayofweek and hour information out of column publish_time and build new column for each\n",
    "df[\"DATOP_year\"] = df[\"DATOP\"].dt.year\n",
    "df[\"DATOP_month\"] = df[\"DATOP\"].dt.month\n",
    "df[\"DATOP_day\"] = df[\"DATOP\"].dt.dayofweek + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_hour_to_period(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'day'\n",
    "    elif 18 <= hour < 24:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df[\"STD_hour\"] = df[\"STD\"].dt.hour\n",
    "df[\"STD_period\"] = df[\"STD_hour\"].apply(map_hour_to_period)\n",
    "\n",
    "df[\"STA_hour\"] = df[\"STA\"].dt.hour\n",
    "df[\"STA_period\"] = df[\"STA_hour\"].apply(map_hour_to_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['DATOP_month'] == 5) & (df['DATOP_year'] == 2016))]\n",
    "df = df[~((df['DATOP_month'] == 2) & (df['DATOP_year'] == 2017))]\n",
    "df = df[~((df['DATOP_month'] == 9) & (df['DATOP_year'] == 2018))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flight_time\"] = (df[\"STA\"] - df[\"STD\"]).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    # cmap=\"Reds\",\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "\n",
    "plt.savefig(\"./img/each-vs-each-wrt-correlation_heatmap.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PP-score matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_COMPUTATIONS:\n",
    "\n",
    "    cols = [\n",
    "        col for col in df.columns\n",
    "        if not col.startswith(\"DATOP_\") and col not in [\"ID\"]\n",
    "    ]\n",
    "    \n",
    "    df_tmp = df[cols]\n",
    "\n",
    "    pp_scores = pps.matrix(df_tmp)[[\"x\", \"y\", \"ppscore\"]].pivot(\n",
    "        columns=\"x\", index=\"y\", values=\"ppscore\"\n",
    "    )\n",
    "\n",
    "    pp_scores = pp_scores.round(2)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.heatmap(\n",
    "        pp_scores,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        # cmap=\"Reds\",\n",
    "        linewidths=0.5,\n",
    "        annot=True,\n",
    "    )\n",
    "\n",
    "    plt.savefig(\"./img/each-vs-each-wrt-pp-score_heatmap.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_COMPUTATIONS:\n",
    "    sns.pairplot(df)\n",
    "\n",
    "    plt.savefig(\"./img/each-vs-each-wrt-distribution_scatterplot.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOP_years = df[\"DATOP_year\"].unique()\n",
    "\n",
    "for status in DATOP_years:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df_year = df[df[\"DATOP_year\"] == status]\n",
    "    df_year[\"DATOP_month\"].hist(bins=12)\n",
    "    plt.title(f\"Flight Distribution per Month – {status}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Flights\")\n",
    "    plt.xticks(range(1, 13))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"./img/month-to-sum-flight-on-status-eq-{status}_line.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for status in DATOP_years:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df_year = df[df[\"DATOP_year\"] == status]\n",
    "    df_year.groupby(\"DATOP_month\")[\"target\"].sum().plot(\n",
    "        kind=\"line\",\n",
    "        title=f\"Monthly Sum of Target for {status}\",\n",
    "        xlabel=\"Month\",\n",
    "        ylabel=\"Sum of Target\",\n",
    "    )\n",
    "    plt.savefig(f\"./img/month-to-sum-delay-on-status-eq-{status}_line.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing months can be found in the test data set (sic!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (a.k.a. A Feeble Try), Version I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis**: The flight delay can be predicted from the Aircraft Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=[\"AC\"], prefix=\"AC\")\n",
    "\n",
    "y = df.target\n",
    "X = df_encoded.drop(\"target\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RSEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit -- Predict -- Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_encoded.columns if col.startswith(\"AC_\")]\n",
    "\n",
    "X_0 = X_train[cols]\n",
    "y_0 = y_train\n",
    "X_1 = X_test[cols]\n",
    "y_1 = y_test\n",
    "\n",
    "# model = KNeighborsRegressor(n_neighbors=3)\n",
    "# # model = LinearRegression()\n",
    "\n",
    "# model.fit(X_0, y_0)\n",
    "\n",
    "# y_pred = model.predict(X_1)\n",
    "\n",
    "# mse = mean_squared_error(y_1, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# r2 = r2_score(y_1, y_pred)\n",
    "\n",
    "# # print(\"Coefficients:\", linreg.coef_)\n",
    "# # print(\"Intercept:\", model.intercept_)\n",
    "# print(\"Root Mean Squared Error:\", rmse)\n",
    "# # print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.to_csv(\"data/X_test.csv\")\n",
    "# y_test.to_csv(\"data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Considerations About Flight Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# die Verteilung der Verspätungen unter Abluegen und Ankuenften\n",
    "# Durchschnittliche Verspätung pro Abflughafen\n",
    "dep_delay = df.groupby(\"DEPSTN\")[\"target\"].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "dep_delay.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Durchschnittliche Verspätung pro Abflughafen\")\n",
    "plt.xlabel(\"Abflughafen\")\n",
    "plt.ylabel(\"Durchschnittliche Verspätung (Minuten)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./img/dep-to-avg-delay_hist.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchschnittliche Verspätung pro Ankunftsflughafen\n",
    "arr_delay = df.groupby(\"ARRSTN\")[\"target\"].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "arr_delay.plot(kind=\"bar\", color=\"salmon\")\n",
    "plt.title(\"Durchschnittliche Verspätung pro Ankunftsflughafen\")\n",
    "plt.xlabel(\"Ankunftsflughafen\")\n",
    "plt.ylabel(\"Durchschnittliche Verspätung (Minuten)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./img/dest-to-avg-delay_hist.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot-Tabelle für Heatmap\n",
    "route_delay = df.pivot_table(\n",
    "    index=\"ARRSTN\", columns=\"DEPSTN\", values=\"target\", aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(route_delay, cmap=\"Reds\", linewidths=0.5, annot=False)\n",
    "plt.title(\"Durchschnittliche Verspätung zwischen Abflug- und Ankunftsflughäfen\")\n",
    "plt.xlabel(\"Ankunftsflughafen\")\n",
    "plt.ylabel(\"Abflughafen\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./img/dep-vs-dest-wrt-avg-delay_heatmap.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x=\"DEPSTN\", y=\"target\", data=df)\n",
    "plt.title(\"Verteilung der Verspätungen pro Abflughafen\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(f\"./img/airport-to-delay_boxplot.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = df.pivot_table(\n",
    "    index=\"DEPSTN\", columns=\"ARRSTN\", values=\"target\", aggfunc=\"mean\"\n",
    ")\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot, annot=False, cmap=\"Reds\")\n",
    "plt.title(\"Durchschnittliche Verspätung je Flugroute (in Minuten)\")\n",
    "plt.xlabel(\"Ankunftsflughafen\")\n",
    "plt.ylabel(\"Abflughafen\")\n",
    "plt.savefig(f\"./img/dep-vs-dest-wrt-delay_heatmap.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dep = df[\"DEPSTN\"].value_counts().head(10)\n",
    "avg_delay_dep = df.groupby(\"DEPSTN\")[\"target\"].mean().loc[top_dep.index]\n",
    "\n",
    "summary = pd.DataFrame({\"Fluganzahl\": top_dep, \"Ø Verspätung (Min.)\": avg_delay_dep})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"DEPSTN\"] == \"TUN\"][\"target\"].hist(bins=30)\n",
    "plt.title(\"Verspätungsverteilung – Abflughafen TUN\")\n",
    "plt.xlabel(\"Verspätung in Minuten\")\n",
    "plt.ylabel(\"Anzahl Flüge\")\n",
    "plt.savefig(f\"./img/airport-to-delay-on-dest-eq-TUN_boxplot.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling stuff Moritz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(\n",
    "    df, columns=[\"DATOP_day\"], prefix=\"day\", drop_first=True, dtype=int\n",
    ")\n",
    "df2 = pd.get_dummies(\n",
    "    df2, columns=[\"DATOP_year\"], prefix=\"yr\", drop_first=True, dtype=int\n",
    ")\n",
    "df2 = pd.get_dummies(\n",
    "    df2, columns=[\"DATOP_month\"], prefix=\"mon\", drop_first=True, dtype=int\n",
    ")\n",
    "df2 = pd.get_dummies(df2, columns=[\"DEPSTN\"], prefix=\"dep\", drop_first=True, dtype=int)\n",
    "df2 = pd.get_dummies(df2, columns=[\"ARRSTN\"], prefix=\"arr\", drop_first=True, dtype=int)\n",
    "df2 = pd.get_dummies(df2, columns=[\"AC\"], prefix=\"ac\", drop_first=True, dtype=int)\n",
    "df2 = pd.get_dummies(\n",
    "    df2, columns=[\"STD_period\"], prefix=\"std\", drop_first=True, dtype=int\n",
    ")\n",
    "df2 = pd.get_dummies(\n",
    "    df2, columns=[\"STA_period\"], prefix=\"sta\", drop_first=True, dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2.target\n",
    "X = df2.drop(\"target\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RSEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\"day_\", \"yr_\", \"mt_\", \"ac_\", \"dep_\", \"arr_\", \"std_\", \"sta_\"]\n",
    "\n",
    "# Collect columns that match those prefixes\n",
    "feature_cols = [\n",
    "    col for col in df2.columns if any(col.startswith(p) for p in prefixes)\n",
    "] + [\"flight_time\"]\n",
    "\n",
    "x0 = X_train[feature_cols]\n",
    "x1 = X_test[feature_cols]\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "# model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "model.fit(x0, y_train)\n",
    "y_pred_test = model.predict(x1)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print(r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2,5],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # or use 'r2' if you prefer\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x0, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = best_model.predict(x1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = XGBRegressor(random_state=42, verbosity=0)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10, 30],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(x0, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = best_model.predict(x1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
